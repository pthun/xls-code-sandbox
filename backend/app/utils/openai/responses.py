"""Helpers for invoking the OpenAI Responses API."""

from __future__ import annotations

import json
import re
from dataclasses import dataclass
from typing import Any, List, Literal, Sequence, cast

from openai import AsyncOpenAI
from openai.types.responses import (
    FunctionToolParam,
    Response,
    ResponseFunctionToolCallParam,
    ResponseInputItemParam,
    ResponseOutputMessage,
    ResponseOutputText,
    ResponseUsage,
)
from openai.types.responses.easy_input_message_param import EasyInputMessageParam

from ..misc.typeguards import is_any_list, is_str_any_dict
from ..tools.base import ResponseTool, ToolExecutionResult
from ..tools.registry import registry as tool_registry

RoleLiteral = Literal["user", "assistant", "system", "developer"]


@dataclass(slots=True)
class _PendingToolCall:
    """Container representing a tool invocation generated by the model."""

    name: str
    call_id: str
    arguments: dict[str, Any]
    arguments_raw: str | None

    def as_param(self) -> ResponseFunctionToolCallParam:
        """Expose the call details in Responses-compatible form."""

        arguments = (
            self.arguments_raw
            if self.arguments_raw is not None
            else json.dumps(self.arguments, separators=(",", ":"))
        )
        return cast(
            ResponseFunctionToolCallParam,
            {
                "type": "function",
                "id": self.call_id,
                "function": {
                    "name": self.name,
                    "arguments": arguments,
                },
            },
        )


async def call_openai_responses(
    *,
    api_key: str,
    system_prompt: str,
    messages: Sequence[tuple[RoleLiteral, str]],
    model_name: str,
    tool_names: Sequence[str] | None = None,
    max_tool_iterations: int = 3,
) -> tuple[
    Response,
    str,
    str | None,
    list[str],
    list[dict[str, Any]],
    list[dict[str, Any]],
    bool,
    bool,
    int | None,
    int | None,
    int | None,
    str,
    list[ToolExecutionResult],
]:
    """Call the Responses API and return raw/parsed artefacts.

    The returned tuple contains:
        - the raw Response object
        - display text with code/pip tags removed
        - latest code block (or None)
        - list of pip packages
        - prompt token usage (if reported)
        - completion token usage (if reported)
        - total token usage (if reported)
        - executed tool call details (if any were triggered)
    Raises:
        KeyError: If a requested tool name is not registered.
        ValueError: If a tool definition is malformed.
    """

    client = AsyncOpenAI(api_key=api_key)
    prompt = _build_prompt(system_prompt, messages)
    history: list[Any] = list(prompt)

    available_tools: list[FunctionToolParam] = []
    tool_handlers: dict[str, ResponseTool] = {}

    if tool_names:
        seen: set[str] = set()
        for name in tool_names:
            if name in seen:
                continue
            seen.add(name)
            tool = tool_registry.get(name)
            definition = _normalize_tool_definition(tool.definition)
            if not (_model_to_dict(definition).get("name")):
                msg = f"Tool '{name}' definition is missing a name attribute"
                raise ValueError(msg)
            available_tools.append(definition)
            tool_handlers[tool.name] = tool

    executed_tools: list[ToolExecutionResult] = []

    response: Response | None = None

    for _iteration in range(max(max_tool_iterations, 0) + 1):
        response = await client.responses.create(
            model=model_name,
            input=history,
            tools=available_tools,
        )

        outputs = list(response.output or [])
        if outputs:
            history.extend(outputs)

        tool_calls = _collect_tool_calls(outputs)
        if not tool_calls:
            break

        if not tool_handlers:
            raise RuntimeError(
                "OpenAI requested tool execution but no registered tools were provided."
            )

        for call in tool_calls:
            tool = tool_handlers.get(call.name)
            if tool is None:
                msg = f"No executor registered for tool '{call.name}'"
                raise KeyError(msg)

            execution = await tool.invoke(arguments=call.arguments or None)

            tool_call_param = call.as_param()
            tool_output_param = _prepare_tool_output(execution.output, call.call_id)

            executed_tools.append(
                ToolExecutionResult(
                    tool_call=tool_call_param,
                    output=tool_output_param,
                    response=execution.response,
                    usage=execution.usage,
                )
            )

            history.append(tool_output_param)
    else:  # pragma: no cover - defensive guard for runaway tool loops
        msg = "Exceeded maximum tool iterations without completing the response"
        raise RuntimeError(msg)

    if response is None:  # pyright: ignore[reportUnnecessaryComparison]
        raise RuntimeError("Failed to obtain a response from OpenAI")

    raw_text = _extract_text(response)
    code_blocks = _extract_tagged_blocks(raw_text, "CodeOutput")
    pip_blocks = _extract_tagged_blocks(raw_text, "Pip")
    params_blocks = _extract_tagged_blocks(raw_text, "Params")
    file_blocks = _extract_tagged_blocks(raw_text, "FileList")

    code = code_blocks[-1] if code_blocks else None
    pip_packages = _split_packages(pip_blocks)
    params_present = bool(params_blocks)
    file_present = bool(file_blocks)
    params_model = _parse_json_array(params_blocks[-1] if params_blocks else None)
    file_requirements = _parse_json_array(file_blocks[-1] if file_blocks else None)
    display_text = _strip_tags(raw_text, ("CodeOutput", "Pip", "Params", "FileList"))

    usage: ResponseUsage | None = response.usage
    prompt_tokens = usage.input_tokens if usage else None
    completion_tokens = usage.output_tokens if usage else None
    total_tokens = usage.total_tokens if usage else None

    return (
        response,
        display_text,
        code,
        pip_packages,
        params_model,
        file_requirements,
        params_present,
        file_present,
        prompt_tokens,
        completion_tokens,
        total_tokens,
        raw_text,
        executed_tools,
    )


def _build_prompt(
    system_prompt: str, messages: Sequence[tuple[RoleLiteral, str]]
) -> List[ResponseInputItemParam]:
    prompt: List[ResponseInputItemParam] = [
        EasyInputMessageParam(
            role="system",
            content=system_prompt.strip(),
            type="message",
        )
    ]

    for role, content in messages:
        text = content.strip()
        if not text:
            continue
        prompt.append(
            EasyInputMessageParam(
                role=role,
                content=text,
                type="message",
            )
        )

    return prompt

def _extract_text(response: Response) -> str:
    segments: List[str] = []
    for item in response.output or []:
        if isinstance(item, ResponseOutputMessage):
            for content in item.content:
                if isinstance(content, ResponseOutputText):
                    segments.append(content.text)
    if segments:
        return "".join(segments)
    raise ValueError("OpenAI response did not include textual content")


def _extract_tagged_blocks(text: str, tag: str) -> list[str]:
    pattern = re.compile(rf"<{tag}>(.*?)</{tag}>", re.IGNORECASE | re.DOTALL)
    return [match.group(1).strip() for match in pattern.finditer(text)]


def _split_packages(blocks: Sequence[str]) -> list[str]:
    packages: list[str] = []
    for block in blocks:
        for line in block.splitlines():
            pkg = line.strip()
            if pkg:
                packages.append(pkg)
    return packages


def _parse_json_array(block: str | None) -> list[dict[str, Any]]:
    if not block:
        return []
    try:
        data = json.loads(block)
    except json.JSONDecodeError:
        return []
    if is_any_list(data):
        return [item for item in data if isinstance(item, dict)]
    return []


def _strip_tags(text: str, tags: Sequence[str]) -> str:
    cleaned = text
    for tag in tags:
        cleaned = re.sub(rf"<{tag}>.*?</{tag}>", "", cleaned, flags=re.IGNORECASE | re.DOTALL)
    return cleaned.strip()


def _collect_tool_calls(items: Sequence[Any]) -> list[_PendingToolCall]:
    """Extract tool call requests emitted by the model."""

    calls: list[_PendingToolCall] = []
    for item in items:
        payload = _model_to_dict(item)
        item_type = payload.get("type")

        if item_type in {"function_call", "tool_call"}:
            call = _pending_call_from_payload(payload)
            if call is not None:
                calls.append(call)
            continue

        if item_type != "message":
            continue

        for content in payload.get("content", []):
            content_payload = _model_to_dict(content)
            content_type = content_payload.get("type")
            if content_type not in {"function_call", "tool_call"}:
                continue
            call = _pending_call_from_payload(content_payload)
            if call is not None:
                calls.append(call)

    return calls


def _pending_call_from_payload(payload: dict[str, Any]) -> _PendingToolCall | None:
    """Convert a raw payload into a structured pending tool call."""

    call_id = payload.get("call_id") or payload.get("id")
    name = payload.get("name")
    if not call_id or not isinstance(call_id, str):
        return None
    if not name or not isinstance(name, str):
        function_payload = payload.get("function")
        if is_str_any_dict(function_payload):
            candidate = function_payload.get("name")
            if isinstance(candidate, str):
                name = candidate
    if not name or not isinstance(name, str):
        return None

    raw_arguments: str | None = None
    if isinstance(payload.get("arguments"), str):
        raw_arguments = payload["arguments"]
    else:
        function_payload = payload.get("function")
        if is_str_any_dict(function_payload):
            arguments_value = function_payload.get("arguments")
            if isinstance(arguments_value, str):
                raw_arguments = arguments_value

    arguments = _parse_tool_arguments(raw_arguments)

    return _PendingToolCall(
        name=name,
        call_id=call_id,
        arguments=arguments,
        arguments_raw=raw_arguments,
    )


def _model_to_dict(value: Any) -> dict[str, Any]:
    """Best-effort conversion of SDK models into plain dictionaries."""

    if is_str_any_dict(value):
        return value
    if hasattr(value, "model_dump") and callable(value.model_dump):  # pydantic v2 models
        try:
            return value.model_dump()
        except Exception:  # pragma: no cover - defensive
            return {}
    if hasattr(value, "dict") and callable(value.dict):  # pydantic v1 compatibility
        try:
            return value.dict()
        except Exception:  # pragma: no cover - defensive
            return {}
    return {}


def _parse_tool_arguments(arguments_json: str | None) -> dict[str, Any]:
    """Parse tool arguments emitted as JSON, yielding a dictionary."""

    if not arguments_json:
        return {}
    try:
        parsed = json.loads(arguments_json)
    except json.JSONDecodeError:
        return {}
    if is_str_any_dict(parsed):
        return parsed
    return {}


def _prepare_tool_output(
    output: ResponseInputItemParam, call_id: str
) -> ResponseInputItemParam:
    """Ensure the tool output references the originating tool call."""

    payload = _model_to_dict(output)

    if payload:
        prepared = dict(payload)
        output_type = prepared.get("type")

        if output_type == "tool_result":
            prepared["tool_call_id"] = call_id
            return cast(ResponseInputItemParam, prepared)

        if output_type == "function_call_output":
            prepared["call_id"] = call_id
            if "output" in prepared and not isinstance(prepared["output"], str):
                prepared["output"] = json.dumps(prepared["output"])
            return cast(ResponseInputItemParam, prepared)

    serialized = output if isinstance(output, str) else json.dumps(output)
    return cast(
        ResponseInputItemParam,
        {
            "type": "function_call_output",
            "call_id": call_id,
            "output": serialized,
        },
    )


def _normalize_tool_definition(
    definition: FunctionToolParam,
) -> FunctionToolParam:
    """Ensure the tool definition matches the schema expected by the API."""

    payload = _model_to_dict(definition)
    name = payload.get("name")
    if isinstance(name, str) and name:
        return cast(FunctionToolParam, payload)

    function_payload = payload.get("function")
    if not is_str_any_dict(function_payload):
        return cast(FunctionToolParam, payload)

    fn_name = function_payload.get("name")
    if not isinstance(fn_name, str) or not fn_name:
        return cast(FunctionToolParam, payload)

    normalized: dict[str, Any] = {
        "type": payload.get("type", "function"),
        "name": fn_name,
    }

    description = function_payload.get("description")
    if isinstance(description, str) and description:
        normalized["description"] = description

    parameters = function_payload.get("parameters")
    if parameters is not None:
        normalized["parameters"] = parameters

    return cast(FunctionToolParam, normalized)
